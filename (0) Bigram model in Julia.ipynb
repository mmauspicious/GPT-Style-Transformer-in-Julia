{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28649c3c-5b92-4825-b8f3-8e0e57e08722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict_next_words (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This sample code reads in a text corpus, builds a bigram model by counting adjacent word pairs, and then generates text based on the computed probabilities.\n",
    "\n",
    "using Random\n",
    "using StatsBase  # Import StatsBase to use the sample function\n",
    "\n",
    "# The line using StatsBase makes the sample function available. \n",
    "# If you haven't installed StatsBase, you can do so by running using Pkg; Pkg.add(\"StatsBase\") in the Julia REPL.\n",
    "\n",
    "# Build the bigram model as a dictionary of dictionaries\n",
    "function build_bigram_model(corpus::String)\n",
    "    # Tokenize the corpus by splitting on whitespace and converting to lowercase\n",
    "    tokens = split(lowercase(corpus))\n",
    "    model = Dict{String, Dict{String, Int64}}()\n",
    "    \n",
    "    # Count bigrams\n",
    "    for i in 1:length(tokens)-1\n",
    "        current = tokens[i]\n",
    "        next_word = tokens[i+1]\n",
    "        if haskey(model, current)\n",
    "            model[current][next_word] = get(model[current], next_word, 0) + 1\n",
    "        else\n",
    "            model[current] = Dict(next_word => 1)\n",
    "        end\n",
    "    end\n",
    "    return model\n",
    "end\n",
    "\n",
    "# The build_bigram_model function tokenizes the input corpus and builds a dictionary where each word maps to another dictionary containing the counts of words that follow it.\n",
    "\n",
    "# Generate text based on the bigram model\n",
    "function generate_text(model::Dict{String, Dict{String, Int64}}, start_word::String, num_words::Int)\n",
    "    current_word = start_word\n",
    "    output = [current_word]\n",
    "    \n",
    "    for _ in 2:num_words\n",
    "        if !haskey(model, current_word)\n",
    "            break  # Stop if no continuation is found\n",
    "        end\n",
    "        \n",
    "        # Extract possible next words and their counts\n",
    "        next_options = model[current_word]\n",
    "        words = collect(keys(next_options))\n",
    "        counts = [next_options[word] for word in words]\n",
    "        \n",
    "        # Compute probabilities and sample the next word using weighted random selection\n",
    "        total = sum(counts)\n",
    "        probs = [c / total for c in counts]\n",
    "        # Use StatsBase.sample to randomly select an index based on weights\n",
    "        index = sample(1:length(words), Weights(probs))\n",
    "        current_word = words[index]\n",
    "        push!(output, current_word)\n",
    "    end\n",
    "    \n",
    "    return join(output, \" \")\n",
    "end\n",
    "\n",
    "# The generate_text function uses the sample function from StatsBase to select the next word based on the weighted probabilities computed from the bigram frequencies.\n",
    "\n",
    "# New function: Predict and display next words with their probabilities for a given word\n",
    "function predict_next_words(model::Dict{String, Dict{String, Int64}}, word::String)\n",
    "    if !haskey(model, word)\n",
    "        println(\"No predictions available for the word \\\"$word\\\".\")\n",
    "        return\n",
    "    end\n",
    "    next_options = model[word]\n",
    "    total = sum(values(next_options))\n",
    "    println(\"Predicted next words for \\\"$word\\\":\")\n",
    "    for (w, count) in next_options\n",
    "        prob = round(count / total, digits=2)\n",
    "        println(\"  $w: $prob\")\n",
    "    end\n",
    "end\n",
    "\n",
    "# This function checks if a given word exists in the model. \n",
    "# If it does, it computes the probability for each subsequent word based on their counts and prints them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b536151-d711-4f12-8dba-a7aac4b657eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      "this language model will help generate text based on bigram frequencies.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "corpus = \"\"\"\n",
    "This is a sample text for our bigram language model. This language model will help generate text based on bigram frequencies.\n",
    "\"\"\"\n",
    "\n",
    "model = build_bigram_model(corpus)\n",
    "println(\"Generated text:\")\n",
    "println(generate_text(model, \"this\", 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf03959c-7779-436a-b5cf-c8a0d4f11c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text with model2 starting with 'data':\n",
      "data science, models are essential. the bigram language model is a simple model. it helps\n",
      "\n",
      "Prediction of next words for 'model':\n",
      "Predicted next words for \"model\":\n",
      "  is: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Below is an extended example showing how you can not only generate text but also inspect the model’s learned probabilities for a given word. \n",
    "# In this second example, we add a helper function to print the predicted next words along with their probabilities.\n",
    "\n",
    "# ----- Example Usage 2 -----\n",
    "\n",
    "# A new corpus for demonstration\n",
    "corpus = \"\"\"\n",
    "In data science, models are essential. The bigram language model is a simple model. \n",
    "It helps in understanding word pair frequencies. Data science projects can involve large text corpora.\n",
    "\"\"\"\n",
    "\n",
    "# Build the model from the new corpus\n",
    "model2 = build_bigram_model(corpus)\n",
    "\n",
    "# Generate text starting with the word \"data\"\n",
    "println(\"Generating text with model2 starting with 'data':\")\n",
    "println(generate_text(model2, \"data\", 15))\n",
    "\n",
    "println(\"\\nPrediction of next words for 'model':\")\n",
    "predict_next_words(model2, \"model\")\n",
    "\n",
    "# A different corpus is used to build a second model (model2). \n",
    "# We generate text starting with the word \"data\" and then print out the probabilities of possible next words following \"model\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b53bf62a-f949-4cac-a829-287cae8d668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output looks as expected for a demonstration with a small corpus:\n",
    "\n",
    "    # Generated Text:\n",
    "    # The text generated starting with \"data\" reflects the structure of your input corpus. \n",
    "    # The sequence \"data science, models are essential. the bigram language model is a simple model. it helps\" shows that the model is chaining words based on observed bigram frequencies. \n",
    "    # In this case, the text is coherent given the limited training data, though with a larger and more varied corpus, you’d likely see more diversity and less repetition.\n",
    "\n",
    "    # Prediction for \"model\":\n",
    "    # the fact that the predicted next word for \"model\" is \"is\" with a probability of 1.0 indicates that every instance of \"model\" in your corpus was followed by \"is.\" \n",
    "    # This deterministic result is expected with a small dataset and clearly demonstrates that your model is correctly capturing the relationships between word pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c4d79-9b8e-4f75-b203-2a28e49e4b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.0",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
